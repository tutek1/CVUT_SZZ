# 10. ZpÅ¯soby popisu rozdÄ›lenÃ­  nÃ¡hodnÃ½ch veliÄin a vektorÅ¯. Odhady parametrÅ¯ rozdÄ›lenÃ­. ZÃ¡kladnÃ­ statistickÃ© testy. MarkovskÃ© Å™etÄ›zce a jejich asymptotickÃ© vlastnosti.

----------

http://cmp.felk.cvut.cz/~navara/stat/PMS_ebook.pdf
http://cmp.felk.cvut.cz/~navara/stat/

----------

https://cs.wikipedia.org/wiki/Rozd%C4%9Blen%C3%AD_pravd%C4%9Bpodobnosti - dobrÃ½ shrnutÃ­ popisu nÃ¡hodnÃ½ch veliÄin a vektorÅ¯

TestovÃ¡nÃ­ hypotÃ©z - pÅ™Ã­klad
[https://youtu.be/VMRZO_yYWrA](https://youtu.be/VMRZO_yYWrA)

# ZÃ¡kladnÃ­ pojmy pravdÄ›podobnosti

**Laplaceova (klasickÃ¡) pravdÄ›podobnost**

- **NÃ¡hodnÃ½ pokus** mÃ¡ n âˆˆ N rÅ¯znÃ½ch, vzÃ¡jemnÄ› se vyluÄujÃ­cÃ­ch vÃ½sledkÅ¯, kterÃ© jsou stejnÄ› moÅ¾nÃ©.
- **ElementÃ¡rnÃ­ jevy** = vÃ½sledky nÃ¡hodnÃ©ho pokusu
- **MnoÅ¾ina vÅ¡ech elementÃ¡rnÃ­ch jevÅ¯**: Î©
- **Jev** je podmnoÅ¾ina vÅ¡ech elementÃ¡rnÃ­ch jevÅ¯ ( A âŠ† Î© )
- **PravdÄ›podobnost jevu** A : $$P(A) = \frac{|A|}{|\Omega|}$$(ProstÄ› poÄet sprÃ¡vnÃ½ch vÃ½sledkÅ¯ dÄ›leno poÄet vÅ¡ech moÅ¾nÃ½ch)
- **JevovÃ© pole**: vÅ¡echny jevy pozorovatelnÃ© v nÃ¡hodnÃ©m pokusu, zde expÎ© (=mnoÅ¾ina vÅ¡ech podmnoÅ¾in mnoÅ¾iny Î©)

**Kolmogorovova pravdÄ›podobnost**
- ElementÃ¡rnÃ­ch jevÅ¯ (=prvkÅ¯ mnoÅ¾iny Î©) mÅ¯Å¾e bÃ½t nekoneÄnÄ› mnoho, nemusÃ­ bÃ½t stejnÄ› pravdÄ›podobnÃ©
- **Jevy** jsou podmnoÅ¾iny mnoÅ¾iny Î©, ale ne nutnÄ› vÅ¡echny. TvoÅ™Ã­ podmnoÅ¾inu A âŠ† exp Î© , kterÃ¡ splÅˆuje podmÃ­nky Ïƒ-algebry (viz. nÃ­Å¾e).
- **PravdÄ›podobnost** nenÃ­ urÄena strukturou jevÅ¯ jako u Laplaceova modelu, je to funkce P: A â†’ âŸ¨ 0,1 âŸ© , splÅˆujÃ­cÃ­ podmÃ­nky: 
- (P1) P( 1 ) =1,
- (P2) P( â‹ƒn âˆˆ NAn ) = âˆ‘ n âˆˆ N P(An) , pokud jsou mnoÅ¾iny (=jevy) A n , n âˆˆ N , po dvou nesluÄitelnÃ©
- **PravdÄ›podobnostnÃ­ prostor** je trojice ( Î© , A ,P ) , kde Î© je neprÃ¡zdnÃ¡ mnoÅ¾ina, A je Ïƒ-algebra podmnoÅ¾in mnoÅ¾iny Î© a P je pravdÄ›podobnost.

**Ïƒ-algebra**
Ïƒ-algebra je teoretickÃ½ koncept vÃ½bÄ›ru jistÃ½ch podmnoÅ¾in danÃ© mnoÅ¾iny, kterÃ½ splÅˆuje pevnÄ› definovanÃ© podmÃ­nky. Koncept Ïƒ-algebry umoÅ¾Åˆuje napÅ™Ã­klad zavÃ©st mÃ­ru, ÄehoÅ¾ se dÃ¡le vyuÅ¾Ã­vÃ¡ zejmÃ©na v matematickÃ© analÃ½ze k budovÃ¡nÃ­ pojmu integrÃ¡l a prÃ¡vÄ› v teorii pravdÄ›podobnosti [wikipedia]. SystÃ©m podmnoÅ¾in A nÄ›jakÃ© mnoÅ¾iny Î© musÃ­ splÅˆovat podmÃ­nky:

1. âˆ… âˆˆ A
2. A âˆˆ A â‡’ A â€¾ âˆˆ A (uzavÅ™enost vÅ¯Äi doplÅˆku)
3. ( âˆ€ n âˆˆ N : A n âˆˆ A ) â‡’ â‹ƒ n âˆˆ N A n âˆˆ A ) (uzavÅ™enost vÅ¯Äi sjednocenÃ­)

NejmenÅ¡Ã­ Ïƒ-algebra podmnoÅ¾in R , kterÃ¡ obsahuje vÅ¡echny intervaly, se nazÃ½vÃ¡ **Borelova Ïƒ-algebra**. Obsahuje vÅ¡echny intervaly otevÅ™enÃ©, uzavÅ™enÃ© i polouzavÅ™enÃ©, i jejich spoÄetnÃ¡ sjednocenÃ­, a nÄ›kterÃ© dalÅ¡Ã­ mnoÅ¾iny, ale je menÅ¡Ã­ ÌneÅ¾ exp R . JejÃ­ prvky nazÃ½vÃ¡me borelovskÃ© mnoÅ¾iny.


# NezaÌvislost naÌhodnyÌch jevÅ¯
Pokud jsou jevy A a B nezÃ¡vislÃ© pak platÃ­:
$P(A\cap B) = P(A) * P(B)$.
$P(A| B) = P(A)$.

$P(A\cup B) = P(A) + P(B) - P(A\cap B)$.

# PodmÃ­nÄ›nÃ¡ pravdÄ›podobnost
$P(A) = P(B)*P(A|B) +P(\neg B)*P(A|\neg B)$
$P(A|B) = \frac{P(A \cap B)}{P(B)}$

# Bayesova vÄ›ta
$P(A|B) = \frac{P(B|A) * P(A)}{P(B)}$
$P(A \cap B) = P(A | B) * P(B) = P(B | A) * P(A)$

# NÃ¡hodnÃ¡ veliÄina (NV)
MÄ›Å™itelnÃ¡ f-ce, jejÃ­ chovÃ¡nÃ­ popisuje neklesajÃ­cÃ­ distribuÄnÃ­ $F_x(t) = P(X <= t)$. PÅ™idÄ›luje hodnoty od 0 do 1. PravdÄ›podobnostnÃ­ fce $p_x(t) = P(X=t)$.

## DiskrÃ©tnÃ­
NabÃ½vÃ¡ koneÄnÃ©ho poÄtu hodnot, distribuÄnÃ­ funkce je schodovitÃ¡
![[DNH14.gif]]

## SpojitÃ¡
NekoneÄnÃ½ poÄet hodnot, P(X = t) = 0
$F_x(t) = \int_{-\inf}^{t} f(t) dt$, kde f(t) je funkce udÃ¡vajÃ­cÃ­ hustotu.
![[Pasted image 20230609192510.jpg]]

## SmÃ­Å¡enÃ¡ NV
SmÄ›s diskrÃ©tnÃ­ a spojitÃ©
$Mix_{c}(D,S), c \in <0,1>$
PlatÃ­: 
$F_x(t) = c F_D(t) + (1-c)F_S(t)$
$p_x(t) = c p_D(t) + (1-c)p_S(t)$

## StÅ™ednÃ­ hodnota
PrÅ¯mÄ›rnÃ¡ hodnota NV, nemusÃ­ existovat
DiskrÃ©tnÃ­ - $\sum t * P(t)$ 
SpojitÃ© - $\int_{-inf}^{inf} t * f_x(t) dt$

- Je to ÄÃ­slo
- $E(x + y) = E(x) + E(y)$  //platÃ­ i pro mÃ­nus
- $E(rX) = r * E(X)$
- $E(r+X) = r + E(X)$

## Rozptyl
Jak moc jsou hodnoty odchÃ½lenÃ© od prÅ¯mÄ›ru E(x)
$D(x) = \sigma^2_x$ (smÄ›rodatnÃ¡ odchylka)
$D(x)=E((x - E(x))^2) = E(x^2) - E^2(x)$
$E(x^2) = E^2(x) + D(x)$

DiskrÃ©tnÃ­ - $E(x^2)=\sum k^2 P(X=k)$
SpojitÃ© - $E(x^2)= \int_{-inf}^{inf} t^2 * f_x(t) dt$

- $D(x) \ge 0$
- $D(x + r) = D(x)$
- $D(r) = 0$
- $D(xr) = D(x) * r^2$

## SmÄ›rodatnÃ¡ odchylka
PrÅ¯mÄ›rnÃ¡ odchylka od prÅ¯mÄ›ru
- $\sigma_x \ge 0$
- $\sigma_r = 0$
- $\sigma_x*r = |r| \sigma_x$
- $\sigma_x+r = \sigma_x$

## NormovanÃ¡ NV
norm X = $\frac{X - E(X)}{\sigma_x}$

## Momenty nÃ¡hodnÃ½ch veliÄin
Pro nÃ¡hodnou veliÄinu N je k-tÃ½ moment definovÃ¡n jako $E (X^k)$
1. moment = stÅ™ednÃ­ hodnota
2. moment = rozptyl + stÅ™ednÃ­ hodnota nadruhou

# ZaÌkladnÄ±Ì typy diskrÃ©tnÃ­ch rozdÄ›lenÄ±Ì
## RovnomÄ›rnÃ©
m moÅ¾nÃ½ch vÃ½sledkÅ¯, kde kaÅ¾dÃ½ mÃ¡ stejnou pravdÄ›podobnost, hod kostkou
$E(x) = (A+B)/2$, kde A je nejmenÅ¡Ã­ hodnota a B nejvÄ›tÅ¡Ã­, $D(x) = (b-a)^2/12$

## AlternativnÃ­
2 moÅ¾nÃ© hodnoty (pst q a (1-q)), hod mincÃ­
$E(x) = P(1) = q, D(x) = q(1 - q)$

## BinomickÃ©
VyjadÅ™uje poÄet ÃºspÄ›chÅ¯ v sÃ©rii m pokusÅ¯, kaÅ¾dÃ½ pokus mÃ¡ pst ÃºspÄ›chu q, poÄet orlÅ¯ pÅ™i hodu 20 mincemi
$E(x) = m*q, D(x) = mq(1 - q)$

## Poissonovo
poÄet udÃ¡lostÃ­ bÄ›hem intervalu dÃ©lky t, $\lambda$ prÅ¯mÄ›rnÃ½ poÄet za jednotku Äasu (tÅ™eba 5 hovorÅ¯ za hodinu)
$E(x)= \lambda = D(x)$

## GeometrickÃ©
PoÄet neÃºspÄ›chÅ¯ nÄ›Å¾ nastane ÃºspÄ›ch, pokaÅ¾dÃ© je stejnÃ¡ pst ÃºspÄ›chu "p", hod mincÃ­ dokud nespadne orel
$E(x) =(1-p)/p, D(x) =(1-p)/p^2$

## HypergeometrickÃ©
NapÅ™Ã­klad "M" losÅ¯ z nichÅ¾ "J" vyhrÃ¡vÃ¡, tak udÃ¡vÃ¡ poÄet vÃ½hernÃ­ch losÅ¯, z vytaÅ¾enÃ½ch "S" losÅ¯
$E(x) = \frac{S*J}{M}, D(x)=\frac{SJ*(M-J)(M-S)}{M^2(M-1)}$

# ZaÌkladnÄ±Ì typy spojitÃ½ch rozdÄ›lenÄ±Ì
## RovnomÄ›rnÃ©
StejnÄ› dlouhÃ© intervaly majÃ­ stejnou pst
$E(x) = (A+B)/2$, kde A je nejmenÅ¡Ã­ hodnota a B nejvÄ›tÅ¡Ã­, $D(x) = (b-a)^2/12$

## NormÃ¡lnÃ­
$E(x) = \mu, D(x) = \sigma^2$

## ExponenciÃ¡lnÃ­
doba ÄekÃ¡nÃ­ mezi 2 nÃ¡slednÃ½mi vÃ½skyty udÃ¡lostÃ­

## Logaritmicko normÃ¡lnÃ­
existuje ğŸ‘

# NÃ¡hodnÃ© vektory
n-rozmÄ›rnÃ¡ nÃ¡hodnÃ¡ veliÄina, mÄ›Å™itelnÃ¡ funkce X: Î© â†’ $R^n$ 
PouÅ¾Ã­vÃ¡me ho v pÅ™Ã­padech, kdy je k popisu vÃ½sledku nÃ¡hodnÃ©ho pokusu nutnÃ© pouÅ¾Ã­t vÃ­ce ÄÃ­sel.
**PÅ™Ã­klad:** Chceme popsat vztah napÅ™. mezi vÃ½Å¡kou a vÃ¡hou osob. K tomu potÅ™ebujeme vÃ­ce informacÃ­ neÅ¾ jen popis jednotlivÃ½ch nÃ¡hodnÃ½ch veliÄin.

**Kovariance**
- urÄuje mÃ­ru statistickÃ© zÃ¡vislosti mezi nÃ¡hodnÃ½mi veliÄinami
- $cov(X,Y) =E(XY) -E(X)E(Y)$
- $cov(X,X) =D(X)$
- $cov(Y,X)=cov(X,Y)$
- $cov(aX+b, cY+d) =a*c*cov( X,Y )$
- $cov(X,Y) =0$ pro nezÃ¡vislÃ© veliÄiny

**Korelace**
- je to kovariace pro normovanÃ© nÃ¡hodnÃ© veliÄiny
- $Ï±(X,Y) = cov(normX, normY)$
- Korelace nabÃ½vÃ¡ hodnot âŸ¨ -1,1 âŸ©
- Pro Ï± =0 Å™Ã­kÃ¡me, Å¾e jsou veliÄiny **nekorelovanÃ©**

pro vektory platÃ­ $D(X+Y) =DX+DY+2cov(X,Y)$ 

# ÄŒebyÅ¡evova nerovnost
![[Pasted image 20230609225558.png]]
![[Pasted image 20230609225606.png]]

# CentrÃ¡lnÃ­ limitnÃ­ vÄ›ta
Pokud platÃ­ pÅ™edpoklady centrÃ¡lnÃ­ limitnÃ­ vÄ›ty, tak vÃ½bÄ›rovÃ½ prÅ¯mÄ›r mÃ¡ jakoÅ¾to nÃ¡hodnÃ¡ veliÄinaÂ _asymptoticky normÃ¡lnÃ­ rozdÄ›lenÃ­_. Jinak Å™eÄeno - rozdÄ›lenÃ­ souÄtu n nezÃ¡vislÃ½ch NV se stejnÃ½m rozdÄ›lenÃ­m se blÃ­Å¾Ã­ k normÃ¡lnÃ­mu rozdÄ›lenÃ­.

**PÅ™edpoklady**:
- StejnÃ© rozdÄ›lenÃ­
- NezÃ¡vislÃ© NV
- $D(x) \ne 0$

$P(X \le a) = P(norm(X) \le \frac{a - EX}{\sqrt{DX}})$
pak lze vyÄÃ­st hodnotu normÃ¡lnÃ­ho rozdÄ›lenÃ­ pro $y \le \frac{a - EX}{\sqrt{DX}}$ z tabulek a mÃ¡me vÃ½sledek.

# ZÃ¡klad statistiky
VÃ½bÄ›rovÃ½ soubor rozsahu n oznaÄujeme jako nÃ¡hodnÃ½ vÃ½bÄ›r $X=( X_1 , â€¦ , X_n)$.

**Statistika** je kaÅ¾dÃ¡ mÄ›Å™itelnÃ¡ funkce, definovanÃ¡ na nÃ¡hodnÃ©m vÃ½bÄ›ru libovolnÃ©ho rozsahu. NÃ¡sledujÃ­cÃ­ statistiky se pouÅ¾Ã­vajÃ­ pro odhady ÄÃ­selnÃ½ch parametrÅ¯.

**EmpirickÃ© rozdÄ›lenÃ­**

**VÃ½bÄ›rovÃ½ prÅ¯mÄ›r**
z nÃ¡hodnÃ©ho vÃ½bÄ›ru $X=( X_1 , â€¦ , X_n )$ je nestrannÃ½ konzistentnÃ­ odhad stÅ™ednÃ­ hodnoty:
![[Pasted image 20230609234003.png]]
**VÃ½bÄ›rovÃ½ rozptyl**
nÃ¡hodnÃ©ho vÃ½bÄ›ru $X=( X_1 , â€¦ , X_n )$ je nestrannÃ½ konzistentnÃ­ odhad stÅ™ednÃ­ rozptylu:
![[Pasted image 20230609234138.png]]


# ObecnÃ© vlastnosti odhadÅ¯ parametrÅ¯. Odhady stÅ™ednÄ±Ì hodnoty, rozptylu, smÄ›rodatnÃ© odchylky, momentÅ¯.
Snaha o odhad neznÃ¡mÃ½ch veliÄin a jejich parametrÅ¯ v zÃ¡vislosti na pozorovanÃ½ch datech.
![[Pasted image 20230610085821.png]]
![[Pasted image 20230610085748.png]]


# Odhady parametrÅ¯ metodou momentÅ¯ 
Metoda momentÅ¯ je zaloÅ¾ena na rovnosti vÃ½bÄ›rovÃ½ch momentÅ¯ a momentÅ¯ rozdÄ›lenÃ­. Nelze jednoznaÄnÄ› rozhodnout, kterÃ¡ z metod dÃ¡vÃ¡ lepÅ¡Ã­ vÃ½sledky. RozhodovÃ¡nÃ­ provÃ¡dÃ­me podle konkrÃ©tnÃ­ situace, nejÄastÄ›ji rozhoduje jednoduchost zÃ­skanÃ½ch vzorcÅ¯. Metoda momentÅ¯
zohledÅˆuje vÅ¡echna data z vÃ½bÄ›ru a volÃ­me ji v pÅ™Ã­padech, kdy je soustava vÄ›rohodnostnÃ­ch rovnic obtÃ­Å¾nÄ› Å™eÅ¡itelnÃ¡.
Pro zÃ¡kladnÃ­ rozdÄ›lenÃ­ dÃ¡vajÃ­ obÄ› metody shodnÃ© vÃ½sledky a v pÅ™Ã­padÄ› sloÅ¾itÄ›jÅ¡Ã­ch rozdÄ›lenÃ­ mÅ¯Å¾eme jako dalÅ¡Ã­ kritÃ©rium uvaÅ¾ovat, kterÃ© vzorce jsou mÃ©nÄ› citlivÃ© na zavleÄenÃ© chyby do hodnot vÃ½bÄ›ru.

PorovnÃ¡me teoretickÃ© k-tÃ© momenty $E(x^k)$ s jejich odhady
![[Pasted image 20230610083945.png]]
Pro k = 1 to je $EX$
Pro k = 2 to je $DX + E(x)^2$


# Odhady parametrÅ¯ metodou maximaÌlnÄ±Ì vÄ›rohodnosti. 
![](https://paper-attachments.dropbox.com/s_FBD9CB5AB5722A3251B1567EA9380D965430509BD4FBBE3BEF1FC8FEA194B83E_1560089316352_image.png)
Obvykle je vhodnÃ© nehledat maximum vÄ›rohodnostnÃ­ funkce pÅ™Ã­mo, ale zlogaritmovat ji. SouÄiny se nÃ¡m zmÄ›nÃ­ na souÄty ale na vÃ½sledek to nebude mÃ­t vliv.

MyÅ¡lenkou tÃ©to metody je, Å¾e hledÃ¡me takovÃ© hodnoty parametrÅ¯, kterÃ© by nejlÃ©pe vysvÄ›tlovali realizaci nÃ¡hodnÃ©ho vÃ½bÄ›ru, tj. pÅ™i kterÃ½ch by pozorovanÃ© vÃ½sledky byly â€œnejmÃ©nÄ› nepravdÄ›podobnÃ©â€.

PravdÄ›podobnost je urÄena pro pÅ™edpovÃ­dÃ¡nÃ­ vÃ½sledkÅ¯ budoucÃ­ho pokusu pÅ™i znÃ¡mÃ©m pravdÄ›podobnostnÃ­m modelu a tudÃ­Å¾ mÃ¡ definiÄnÃ­ obor jevy z nÄ›jakÃ© Ïƒ-algebry. Naopak vÄ›rohodnost vyhodnocuje sÃ©rii pokusÅ¯ jiÅ¾ realizovanÃ½ch a dovoluje jim pÅ™izpÅ¯sobit neznÃ¡mÃ© parametry pravdÄ›podobnostnÃ­ho modelu, a proto je definovÃ¡na na prostoru Î  vÅ¡ech moÅ¾nÃ½ch hodnot parametrÅ¯ rozdÄ›lenÃ­.

**Metoda maximÃ¡lnÃ­ vÄ›rohodnosti** povaÅ¾uje za sprÃ¡vnÃ½ odhad parametrÅ¯ takovÃ© hodnoty, kterÃ© maximalizujÃ­ vÄ›rohodnost.
![[Pasted image 20230610085533.png]]
![[Pasted image 20230610085545.png]]

# IntervalovÃ© odhady.
![[Pasted image 20230610090516.png]]
SymetrickÃ½ odhad ve smyslu, Å¾e se stejnou pst ho pÅ™ekroÄÃ­me nahoru nebo dolÅ¯ (nemusÃ­ bÃ½t vÅ¾dy stejnÃ¡ vzdÃ¡lenost od stÅ™ednÃ­ hodnoty).

# Princip statistickÃ©ho testovaÌnÄ±Ì hypotÃ©z.
Na zÃ¡kladÄ› testu chceme klasifikovat objekty (nebo skupiny objektÅ¯) na zdravÃ©/nemocnÃ©, stÅ™Ã­zlivÃ©/opilÃ©, nevinnÃ©/vinnÃ© apod.

- **NulovÃ¡ hypotÃ©za**: objekt je â€normÃ¡lnÃ­â€œ, â€negativnÃ­â€œ; vÃ½sledkem testu je nÃ¡hodnÃ¡ veliÄina T.
- **AlternativnÃ­ hypotÃ©za**: objekt je â€anomÃ¡lnÃ­â€œ, â€pozitivnÃ­â€œ; vÃ½sledkem (tÃ©hoÅ¾) testu je nÃ¡hodnÃ¡ veliÄina T\* .

**PÅ™Ã­klad**: MÃ¡me povaÅ¾ovat test nemoci za pozitivnÃ­?
**NulovÃ¡ hypotÃ©za H0:** ÄŒlovÄ›k nenÃ­ nakaÅ¾enÃ½.
**AlternativnÃ­ hypotÃ©za H1:** ÄŒlovÄ›k je nakaÅ¾enÃ½.

VÅ¾dy se testuje na nÄ›jakÃ© hladinÄ› vÃ½znamnosti $\alpha$.

# Testy stÅ™ednÄ±Ì hodnoty a rozptylu, porovnaÌnÄ±Ì dvou rozdÄ›lenÄ±Ì
$\bar x$ = EX
Test stÅ™ednÃ­ hodnoty - $t= \frac{\bar x - c}{\sigma} * \sqrt n$ , kde c je odhad EX podle hypotÃ©zy, n stupnÄ› volnosti, pokud neznÃ¡me odchylku tak ji nahradÃ­me odhadem smÄ›rodatnÃ© odchylky.

Test rozptylu - $t= \frac{(n-1) * S_x^2 }{c}$ , kde c je odhad $\sigma^2$ podle hypotÃ©zy, n stupnÄ› volnosti

# Ï‡2 -test
SlouÅ¾Ã­ k testovÃ¡nÃ­ hypotÃ©zy, Å¾e nÃ¡hodnÃ¡ veliÄina mÃ¡ pÅ™edpoklÃ¡danÃ© rozdÄ›lenÃ­. ProtoÅ¾e umÃ­me hypotÃ©zy jen zamÃ­tat, nikdy nepotvrdÃ­me, Å¾e takovÃ© rozdÄ›lenÃ­ opravdu mÃ¡.
![[Pasted image 20230610092048.png]]
![[Pasted image 20230610092106.png]]

# Ï‡2 -test dobrÃ© shody
![[Pasted image 20230610092511.png]]

# Test nezaÌvislosti v kontingenÄnÄ±Ì tabulce.
Je to Ï‡2-test nezÃ¡vislosti dvou rozdÄ›lenÃ­
![[Pasted image 20230610092316.png]]
![[Pasted image 20230610092338.png]]

# MarkovskÃ© Å™etÄ›zce a jejich asymptotickÃ© vlastnosti
https://cs.wikipedia.org/wiki/Markov%C5%AFv_%C5%99et%C4%9Bzec

P â†’ Matice pÅ™echodu - je stochastickÃ¡ - souÄty Å™Ã¡dkÅ¯ je 1
Vektor je sloupcovÃ½ â†’ Wernerovo nÃ¡boÅ¾enstvÃ­.

## Klasifikace stavÅ¯
- NedosaÅ¾itelnÃ© - do takovÃ©ho stavu se nedostaneme nikdy
- AbsorpÄnÃ­ - z takovÃ©ho stavu se nelze dostat
- DosaÅ¾itelnÃ© - lze do nÄ›j dojÃ­t s nenulovou pst
- TrvalÃ½ - pokud z nÄ›j odejdeme je pst 1, Å¾e se sem v budoucnu vrÃ¡tÃ­me, opak je stav pÅ™echodnÃ½
- KomunikujÃ­ - lze z 1. se dostat do 2. a zÃ¡roveÅˆ naopak (silnÄ› souvislÃ½ graf)
- PeriodickÃ© 
![[Pasted image 20230610095958.png]]
- ergodickÃ½ - trvalÃ½ a neperiodickÃ½

## AbsorpÄnÃ­ Å™etÄ›zce
AbsorpÄnÃ­ Å™etÄ›zce jsou takovÃ© Å™etÄ›zce, kterÃ© obsahujÃ­ mimo stavy pÅ™echodnÃ½ i stavy absorpÄnÃ­. Tzn., Å¾e pravdÄ›podobnost setrvÃ¡nÃ­ v takovÃ©m stavu je rovna 1.

![[Pasted image 20230610095536.png]]

## AsymptotickÃ© chovÃ¡nÃ­ MarkovovÃ½ch Å™etÄ›zcÅ¯
Do jakÃ©ho stavu se konverguje po nekoneÄnÄ› mnoha krocÃ­ch t.
PÅ™echodovÃ© stavy - pst konverguje k 0
VÅ¾dy skonÄÃ­ v nÄ›kterÃ©m trvalÃ©m stavu jejich souÄet musÃ­ bÃ½t 1.
![[Pasted image 20230610151741.png]]

## RozloÅ¾itelnÃ© a nerozloÅ¾itelnÃ© Å™etÄ›zce
Asi je tÃ­m myÅ¡leno, Å¾e rozdÄ›litelnÃ© lze rozdÄ›lit na vÃ­ce silnÃ½ch komponent souvislosti, kterÃ© se dajÃ­ Å™eÅ¡it separÃ¡tnÄ›, kdeÅ¾to nerozloÅ¾itelnÃ© majÃ­ pouze jednu komponentu silnÃ© souvislosti + absorpÄnÃ­ stavy.
